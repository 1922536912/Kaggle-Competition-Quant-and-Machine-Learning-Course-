{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition - Quant & Machine Learning Course\n",
    "# Tutorial 13: LSTM (Long Short Term Memory)\n",
    "\n",
    "LSTM details explained https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "Modified based on resource https://github.com/tgjeon/Keras-Tutorials/blob/master/07_lstm.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#from keras import initializations\n",
    "\n",
    "#def init_weights(shape, name=None):\n",
    "#    return initializations.normal(shape, scale=0.01, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    " \n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the sequence\n",
    "        if end_ix > len(sequence)-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "batch_size = 128\n",
    "nb_epoch = 50\n",
    "\n",
    "# Parameters for MNIST dataset\n",
    "img_rows, img_cols = 28, 28\n",
    "nb_classes = 10\n",
    "\n",
    "# Parameters for LSTM network\n",
    "nb_lstm_outputs = 30\n",
    "nb_time_steps = img_rows\n",
    "dim_input_vector = img_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train original shape: (60000, 28, 28)\n",
      "X_train shape: (60000, 28, 28)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print('X_train original shape:', X_train.shape)\n",
    "input_shape = (nb_time_steps, dim_input_vector)\n",
    "\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-13 21:50:26.502311: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 30)                7080      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 7,390\n",
      "Trainable params: 7,390\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(nb_lstm_outputs, input_shape=input_shape))\n",
    "#model.add(LSTM(nb_lstm_outputs, input_shape=input_shape))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-13 21:50:51.477053: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "469/469 [==============================] - 11s 19ms/step - loss: 1.5379 - accuracy: 0.4954\n",
      "Epoch 2/50\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.4612 - accuracy: 0.8648\n",
      "Epoch 3/50\n",
      "469/469 [==============================] - 9s 19ms/step - loss: 0.2859 - accuracy: 0.9149\n",
      "Epoch 4/50\n",
      "469/469 [==============================] - 9s 20ms/step - loss: 0.2088 - accuracy: 0.9372\n",
      "Epoch 5/50\n",
      "469/469 [==============================] - 10s 20ms/step - loss: 0.1655 - accuracy: 0.9522\n",
      "Epoch 6/50\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.1505 - accuracy: 0.9564\n",
      "Epoch 7/50\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.1303 - accuracy: 0.9607\n",
      "Epoch 8/50\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.1139 - accuracy: 0.9663\n",
      "Epoch 9/50\n",
      "469/469 [==============================] - 11s 22ms/step - loss: 0.1004 - accuracy: 0.9710\n",
      "Epoch 10/50\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.0932 - accuracy: 0.9732\n",
      "Epoch 11/50\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0870 - accuracy: 0.9742\n",
      "Epoch 12/50\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0770 - accuracy: 0.9778\n",
      "Epoch 13/50\n",
      "469/469 [==============================] - 11s 22ms/step - loss: 0.0742 - accuracy: 0.9778\n",
      "Epoch 14/50\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0731 - accuracy: 0.9788\n",
      "Epoch 15/50\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0708 - accuracy: 0.9794\n",
      "Epoch 16/50\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0608 - accuracy: 0.9820\n",
      "Epoch 17/50\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0609 - accuracy: 0.9826\n",
      "Epoch 18/50\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0569 - accuracy: 0.9826\n",
      "Epoch 19/50\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0540 - accuracy: 0.9839\n",
      "Epoch 20/50\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.0537 - accuracy: 0.9845\n",
      "Epoch 21/50\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0519 - accuracy: 0.9849\n",
      "Epoch 22/50\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0481 - accuracy: 0.9862\n",
      "Epoch 23/50\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0461 - accuracy: 0.9858\n",
      "Epoch 24/50\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0440 - accuracy: 0.9872\n",
      "Epoch 25/50\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0426 - accuracy: 0.9870\n",
      "Epoch 26/50\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0412 - accuracy: 0.9883\n",
      "Epoch 27/50\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0426 - accuracy: 0.9865\n",
      "Epoch 28/50\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0350 - accuracy: 0.9900\n",
      "Epoch 29/50\n",
      "469/469 [==============================] - 11s 22ms/step - loss: 0.0386 - accuracy: 0.9886\n",
      "Epoch 30/50\n",
      "469/469 [==============================] - 10s 22ms/step - loss: 0.0346 - accuracy: 0.9898\n",
      "Epoch 31/50\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.0348 - accuracy: 0.9895\n",
      "Epoch 32/50\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0333 - accuracy: 0.9899\n",
      "Epoch 33/50\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0309 - accuracy: 0.9900\n",
      "Epoch 34/50\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0308 - accuracy: 0.9902\n",
      "Epoch 35/50\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0289 - accuracy: 0.9909\n",
      "Epoch 36/50\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0303 - accuracy: 0.9908\n",
      "Epoch 37/50\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0290 - accuracy: 0.9916\n",
      "Epoch 38/50\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0275 - accuracy: 0.9913\n",
      "Epoch 39/50\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0261 - accuracy: 0.9919\n",
      "Epoch 40/50\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0243 - accuracy: 0.9922\n",
      "Epoch 41/50\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0268 - accuracy: 0.9922\n",
      "Epoch 42/50\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.0244 - accuracy: 0.9925\n",
      "Epoch 43/50\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0240 - accuracy: 0.9923\n",
      "Epoch 44/50\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0222 - accuracy: 0.9930\n",
      "Epoch 45/50\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0238 - accuracy: 0.9933\n",
      "Epoch 46/50\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0216 - accuracy: 0.9938\n",
      "Epoch 47/50\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0213 - accuracy: 0.9936\n",
      "Epoch 48/50\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.0201 - accuracy: 0.9943\n",
      "Epoch 49/50\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.0206 - accuracy: 0.9935\n",
      "Epoch 50/50\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.0191 - accuracy: 0.9942\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "history = model.fit(X_train, Y_train, epochs=nb_epoch, batch_size=batch_size, shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 1s 7ms/step - loss: 0.0619 - accuracy: 0.9844\n",
      "Summary: Loss over the test dataset: 0.06, Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "evaluation = model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=1)\n",
    "print('Summary: Loss over the test dataset: %.2f, Accuracy: %.2f' % (evaluation[0], evaluation[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant-course",
   "language": "python",
   "name": "quant-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
