{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "irish-insert",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-07-05T17:50:17.732318Z",
     "iopub.status.busy": "2021-07-05T17:50:17.731903Z",
     "iopub.status.idle": "2021-07-05T17:50:19.647572Z",
     "shell.execute_reply": "2021-07-05T17:50:19.646491Z",
     "shell.execute_reply.started": "2021-07-05T17:50:17.732235Z"
    },
    "papermill": {
     "duration": 0.011047,
     "end_time": "2021-07-23T19:09:51.749114",
     "exception": false,
     "start_time": "2021-07-23T19:09:51.738067",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## NN starter\n",
    "\n",
    "A simple NN starter using stock Embedding. \n",
    "\n",
    "Heavily inspired from this notebook for the feature engineering part:\n",
    "https://www.kaggle.com/manels/lgb-starter\n",
    "\n",
    "Embedding layer from :\n",
    "https://www.kaggle.com/colinmorris/embedding-layers\n",
    "\n",
    "Also see:\n",
    "* https://www.kaggle.com/jiashenliu/introduction-to-financial-concepts-and-data\n",
    "* https://www.kaggle.com/c/optiver-realized-volatility-prediction/discussion/250324\n",
    "\n",
    "**I hope it will be useful for other beginners.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "saving-commerce",
   "metadata": {
    "papermill": {
     "duration": 1.179808,
     "end_time": "2021-07-23T19:09:52.939129",
     "exception": false,
     "start_time": "2021-07-23T19:09:51.759321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import glob\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn import preprocessing, model_selection\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "path_root = '~/Documents/deep-learning/quant_course/kaggle_volatility/optiver-realized-volatility-prediction'\n",
    "path_data = '~/Documents/deep-learning/quant_course/kaggle_volatility/optiver-realized-volatility-prediction'\n",
    "path_submissions = '/'\n",
    "\n",
    "target_name = 'target'\n",
    "scores_folds = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "liable-trinidad",
   "metadata": {
    "papermill": {
     "duration": 0.032183,
     "end_time": "2021-07-23T19:09:52.981502",
     "exception": false,
     "start_time": "2021-07-23T19:09:52.949319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff() \n",
    "\n",
    "def realized_volatility(series_log_return):\n",
    "    return np.sqrt(np.sum(series_log_return**2))\n",
    "\n",
    "def rmspe(y_true, y_pred):\n",
    "    return  (np.sqrt(np.mean(np.square((y_true - y_pred) / y_true))))\n",
    "\n",
    "def get_stock_stat(stock_id : int, dataType = 'train'):\n",
    "    key = ['stock_id', 'time_id', 'seconds_in_bucket']\n",
    "    \n",
    "    #Book features\n",
    "    df_book = pd.read_parquet(os.path.join(path_data, 'book_{}.parquet/stock_id={}/'.format(dataType, stock_id)))\n",
    "    df_book['stock_id'] = stock_id\n",
    "    cols = key + [col for col in df_book.columns if col not in key]\n",
    "    df_book = df_book[cols]\n",
    "    \n",
    "    df_book['wap1'] = (df_book['bid_price1'] * df_book['ask_size1'] +\n",
    "                                    df_book['ask_price1'] * df_book['bid_size1']) / (df_book['bid_size1'] + df_book['ask_size1'])\n",
    "    df_book['wap2'] = (df_book['bid_price2'] * df_book['ask_size2'] +\n",
    "                                    df_book['ask_price2'] * df_book['bid_size2']) / (df_book['bid_size2'] + df_book['ask_size2'])\n",
    "    df_book['log_return1'] = df_book.groupby(by = ['time_id'])['wap1'].apply(log_return).fillna(0)\n",
    "    df_book['log_return2'] = df_book.groupby(by = ['time_id'])['wap2'].apply(log_return).fillna(0)\n",
    "    \n",
    "    features_to_apply_realized_volatility = ['log_return'+str(i+1) for i in range(2)]\n",
    "    stock_stat = df_book.groupby(by = ['stock_id', 'time_id'])[features_to_apply_realized_volatility]\\\n",
    "                        .agg(realized_volatility).reset_index()\n",
    "\n",
    "    #Trade features\n",
    "    trade_stat =  pd.read_parquet(os.path.join(path_data,'trade_{}.parquet/stock_id={}'.format(dataType, stock_id)))\n",
    "    trade_stat = trade_stat.sort_values(by=['time_id', 'seconds_in_bucket']).reset_index(drop=True)\n",
    "    trade_stat['stock_id'] = stock_id\n",
    "    cols = key + [col for col in trade_stat.columns if col not in key]\n",
    "    trade_stat = trade_stat[cols]\n",
    "    trade_stat['trade_log_return1'] = trade_stat.groupby(by = ['time_id'])['price'].apply(log_return).fillna(0)\n",
    "    trade_stat = trade_stat.groupby(by = ['stock_id', 'time_id'])[['trade_log_return1']]\\\n",
    "                           .agg(realized_volatility).reset_index()\n",
    "    #Joining book and trade features\n",
    "    stock_stat = stock_stat.merge(trade_stat, on=['stock_id', 'time_id'], how='left').fillna(-999)\n",
    "    \n",
    "    return stock_stat\n",
    "\n",
    "def get_dataSet(stock_ids : list, dataType = 'train'):\n",
    "\n",
    "    stock_stat = Parallel(n_jobs=-1)(\n",
    "        delayed(get_stock_stat)(stock_id, dataType) \n",
    "        for stock_id in stock_ids\n",
    "    )\n",
    "    \n",
    "    stock_stat_df = pd.concat(stock_stat, ignore_index = True)\n",
    "\n",
    "    return stock_stat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-completion",
   "metadata": {
    "papermill": {
     "duration": 0.010292,
     "end_time": "2021-07-23T19:09:53.002566",
     "exception": false,
     "start_time": "2021-07-23T19:09:52.992274",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "american-median",
   "metadata": {
    "papermill": {
     "duration": 466.573553,
     "end_time": "2021-07-23T19:17:39.587365",
     "exception": false,
     "start_time": "2021-07-23T19:09:53.013812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 804 ms, sys: 159 ms, total: 962 ms\n",
      "Wall time: 7min 38s\n",
      "Train shape: (428932, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>target</th>\n",
       "      <th>log_return1</th>\n",
       "      <th>log_return2</th>\n",
       "      <th>trade_log_return1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.006999</td>\n",
       "      <td>0.002006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.001445</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.002476</td>\n",
       "      <td>0.000901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  time_id    target  log_return1  log_return2  trade_log_return1\n",
       "0         0        5  0.004136     0.004499     0.006999           0.002006\n",
       "1         0       11  0.001445     0.001204     0.002476           0.000901"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape: (3, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>row_id</th>\n",
       "      <th>log_return1</th>\n",
       "      <th>log_return2</th>\n",
       "      <th>trade_log_return1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0-4</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0-32</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stock_id  time_id row_id  log_return1  log_return2  trade_log_return1\n",
       "0         0        4    0-4     0.000294     0.000252           0.000295\n",
       "1         0       32   0-32     0.000000     0.000000           0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(path_data, 'train.csv'))\n",
    "%time train_stock_stat_df = get_dataSet(stock_ids = train['stock_id'].unique(), dataType = 'train')\n",
    "train = pd.merge(train, train_stock_stat_df, on = ['stock_id', 'time_id'], how = 'left')\n",
    "print('Train shape: {}'.format(train.shape))\n",
    "display(train.head(2))\n",
    "\n",
    "test = pd.read_csv(os.path.join(path_data, 'test.csv'))\n",
    "test_stock_stat_df = get_dataSet(stock_ids = test['stock_id'].unique(), dataType = 'test')\n",
    "test = pd.merge(test, test_stock_stat_df, on = ['stock_id', 'time_id'], how = 'left').fillna(0)\n",
    "print('Test shape: {}'.format(test.shape))\n",
    "display(test.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-peoples",
   "metadata": {
    "papermill": {
     "duration": 0.011737,
     "end_time": "2021-07-23T19:17:39.611258",
     "exception": false,
     "start_time": "2021-07-23T19:17:39.599521",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training model and making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "blank-determination",
   "metadata": {
    "papermill": {
     "duration": 6.564224,
     "end_time": "2021-07-23T19:17:46.187279",
     "exception": false,
     "start_time": "2021-07-23T19:17:39.623055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "strategic-hygiene",
   "metadata": {
    "papermill": {
     "duration": 0.024257,
     "end_time": "2021-07-23T19:17:46.223582",
     "exception": false,
     "start_time": "2021-07-23T19:17:46.199325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hidden_units = (32,16,8,4,2)\n",
    "stock_embedding_size = 16\n",
    "\n",
    "cat_data = train['stock_id']\n",
    "\n",
    "def base_model():\n",
    "    \n",
    "    # Each instance will consist of two inputs: a single user id, and a single movie id\n",
    "    stock_id_input = keras.Input(shape=(1,), name='stock_id')\n",
    "    num_input = keras.Input(shape=(3,), name='num_data')\n",
    "\n",
    "\n",
    "    #embedding, flatenning and concatenating\n",
    "    stock_embedded = keras.layers.Embedding(max(cat_data)+1, stock_embedding_size, \n",
    "                                           input_length=1, name='stock_embedding')(stock_id_input)\n",
    "    stock_flattened = keras.layers.Flatten()(stock_embedded)\n",
    "    out = keras.layers.Concatenate()([stock_flattened, num_input])\n",
    "    \n",
    "    # Add one or more hidden layers\n",
    "    for n_hidden in hidden_units:\n",
    "\n",
    "        out = keras.layers.Dense(n_hidden, activation='selu')(out)\n",
    "        \n",
    "\n",
    "    #out = keras.layers.Concatenate()([out, num_input])\n",
    "\n",
    "    # A single output: our predicted rating\n",
    "    out = keras.layers.Dense(1, activation='linear', name='prediction')(out)\n",
    "    \n",
    "    model = keras.Model(\n",
    "    inputs = [stock_id_input, num_input],\n",
    "    outputs = out,\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "suited-nurse",
   "metadata": {
    "papermill": {
     "duration": 0.020275,
     "end_time": "2021-07-23T19:17:46.255849",
     "exception": false,
     "start_time": "2021-07-23T19:17:46.235574",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=1e-05, patience=10, verbose=1,\n",
    "    mode='min', baseline=0.25)\n",
    "\n",
    "plateau = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.2, patience=3, verbose=1,\n",
    "    mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dutch-cannon",
   "metadata": {
    "papermill": {
     "duration": 358.316448,
     "end_time": "2021-07-23T19:23:44.584341",
     "exception": false,
     "start_time": "2021-07-23T19:17:46.267893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-25 10:28:27.132279: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-25 10:29:01.631473: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "315/315 [==============================] - 16s 46ms/step - loss: 393.3977 - MSE: 0.0017 - val_loss: 145.0411 - val_MSE: 4.2656e-05\n",
      "Epoch 2/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 9.7886 - MSE: 3.6573e-05 - val_loss: 42.0996 - val_MSE: 1.9605e-05\n",
      "Epoch 3/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 2.9056 - MSE: 1.7136e-05 - val_loss: 7.3128 - val_MSE: 1.0460e-05\n",
      "Epoch 4/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 16.5764 - MSE: 1.4752e-04 - val_loss: 13.3407 - val_MSE: 8.9791e-06\n",
      "Epoch 5/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.9492 - MSE: 8.6558e-06 - val_loss: 2.9506 - val_MSE: 4.3459e-06\n",
      "Epoch 6/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.2775 - MSE: 4.2698e-06 - val_loss: 0.6370 - val_MSE: 2.7339e-06\n",
      "Epoch 7/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.1713 - MSE: 2.8120e-06 - val_loss: 0.1232 - val_MSE: 2.2614e-06\n",
      "Epoch 8/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.1677 - MSE: 2.7212e-06 - val_loss: 0.2313 - val_MSE: 2.4274e-06\n",
      "Epoch 9/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.1469 - MSE: 2.9556e-06 - val_loss: 0.2374 - val_MSE: 2.4891e-06\n",
      "Epoch 10/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.2010 - MSE: 3.0584e-06 - val_loss: 0.0754 - val_MSE: 2.4767e-06\n",
      "Epoch 11/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.1898 - MSE: 2.8936e-06 - val_loss: 0.1457 - val_MSE: 2.0316e-06\n",
      "Epoch 12/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.2175 - MSE: 3.0032e-06 - val_loss: 0.1037 - val_MSE: 2.0698e-06\n",
      "Epoch 13/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.3628 - MSE: 3.7937e-06 - val_loss: 0.2405 - val_MSE: 2.3445e-06\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 14/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0861 - MSE: 2.3442e-06 - val_loss: 0.0687 - val_MSE: 2.2609e-06\n",
      "Epoch 15/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0673 - MSE: 2.2420e-06 - val_loss: 0.0677 - val_MSE: 2.2833e-06\n",
      "Epoch 16/100\n",
      "315/315 [==============================] - 1s 4ms/step - loss: 0.0721 - MSE: 2.2512e-06 - val_loss: 0.0674 - val_MSE: 2.2967e-06\n",
      "Epoch 17/100\n",
      "315/315 [==============================] - 1s 4ms/step - loss: 0.0719 - MSE: 2.2583e-06 - val_loss: 0.0723 - val_MSE: 2.3963e-06\n",
      "Epoch 18/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0743 - MSE: 2.2843e-06 - val_loss: 0.0687 - val_MSE: 2.3460e-06\n",
      "Epoch 19/100\n",
      "315/315 [==============================] - 1s 4ms/step - loss: 0.0749 - MSE: 2.3209e-06 - val_loss: 0.1018 - val_MSE: 2.7486e-06\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 20/100\n",
      "315/315 [==============================] - 2s 5ms/step - loss: 0.0674 - MSE: 2.2950e-06 - val_loss: 0.0653 - val_MSE: 2.1887e-06\n",
      "Epoch 21/100\n",
      "315/315 [==============================] - 1s 4ms/step - loss: 0.0660 - MSE: 2.1928e-06 - val_loss: 0.1173 - val_MSE: 2.8995e-06\n",
      "Epoch 22/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0721 - MSE: 2.2541e-06 - val_loss: 0.0658 - val_MSE: 2.2328e-06\n",
      "Epoch 23/100\n",
      "315/315 [==============================] - 1s 5ms/step - loss: 0.0693 - MSE: 2.3028e-06 - val_loss: 0.0688 - val_MSE: 2.0759e-06\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 24/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0654 - MSE: 2.2216e-06 - val_loss: 0.0649 - val_MSE: 2.1800e-06\n",
      "Epoch 25/100\n",
      "315/315 [==============================] - 1s 4ms/step - loss: 0.0669 - MSE: 2.2109e-06 - val_loss: 0.0686 - val_MSE: 2.3241e-06\n",
      "Epoch 26/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0677 - MSE: 2.1846e-06 - val_loss: 0.0653 - val_MSE: 2.2226e-06\n",
      "Epoch 27/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0637 - MSE: 2.2224e-06 - val_loss: 0.0652 - val_MSE: 2.2049e-06\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Epoch 28/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0641 - MSE: 2.2434e-06 - val_loss: 0.0654 - val_MSE: 2.1475e-06\n",
      "Epoch 29/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0654 - MSE: 2.2459e-06 - val_loss: 0.0649 - val_MSE: 2.1888e-06\n",
      "Epoch 30/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0649 - MSE: 2.2173e-06 - val_loss: 0.0649 - val_MSE: 2.1765e-06\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.199999628122896e-06.\n",
      "Epoch 31/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0654 - MSE: 2.2266e-06 - val_loss: 0.0648 - val_MSE: 2.1777e-06\n",
      "Epoch 32/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0661 - MSE: 2.2130e-06 - val_loss: 0.0648 - val_MSE: 2.1838e-06\n",
      "Epoch 33/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0652 - MSE: 2.2695e-06 - val_loss: 0.0648 - val_MSE: 2.1805e-06\n",
      "Epoch 34/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0667 - MSE: 2.2255e-06 - val_loss: 0.0651 - val_MSE: 2.2109e-06\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 6.399999165296323e-07.\n",
      "Epoch 35/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0640 - MSE: 2.2054e-06 - val_loss: 0.0649 - val_MSE: 2.1764e-06\n",
      "Epoch 36/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0654 - MSE: 2.2290e-06 - val_loss: 0.0648 - val_MSE: 2.1869e-06\n",
      "Epoch 37/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0635 - MSE: 2.2057e-06 - val_loss: 0.0649 - val_MSE: 2.1900e-06\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.2799998785339995e-07.\n",
      "Epoch 38/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0645 - MSE: 2.2228e-06 - val_loss: 0.0648 - val_MSE: 2.1806e-06\n",
      "Epoch 39/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0639 - MSE: 2.2196e-06 - val_loss: 0.0648 - val_MSE: 2.1813e-06\n",
      "Epoch 40/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0640 - MSE: 2.2286e-06 - val_loss: 0.0648 - val_MSE: 2.1807e-06\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.5599996433811613e-08.\n",
      "Epoch 41/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0654 - MSE: 2.2451e-06 - val_loss: 0.0648 - val_MSE: 2.1798e-06\n",
      "Epoch 00041: early stopping\n",
      "Fold 1 NN: 0.25463\n",
      "CV 2/4\n",
      "Epoch 1/100\n",
      "315/315 [==============================] - 17s 50ms/step - loss: 77.2889 - MSE: 3.9914e-04 - val_loss: 0.6929 - val_MSE: 1.1676e-05\n",
      "Epoch 2/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.2540 - MSE: 1.1055e-05 - val_loss: 0.2178 - val_MSE: 9.1167e-06\n",
      "Epoch 3/100\n",
      "315/315 [==============================] - 1s 4ms/step - loss: 0.3498 - MSE: 1.0738e-05 - val_loss: 0.2321 - val_MSE: 8.2963e-06\n",
      "Epoch 4/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.2848 - MSE: 8.9498e-06 - val_loss: 0.1945 - val_MSE: 8.5184e-06\n",
      "Epoch 5/100\n",
      "315/315 [==============================] - 1s 4ms/step - loss: 0.1748 - MSE: 7.1856e-06 - val_loss: 0.1533 - val_MSE: 6.5251e-06\n",
      "Epoch 6/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.1199 - MSE: 4.6831e-06 - val_loss: 0.0828 - val_MSE: 2.2031e-06\n",
      "Epoch 7/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0735 - MSE: 2.4009e-06 - val_loss: 0.0737 - val_MSE: 2.6111e-06\n",
      "Epoch 8/100\n",
      "315/315 [==============================] - 1s 5ms/step - loss: 0.0756 - MSE: 2.4143e-06 - val_loss: 0.0711 - val_MSE: 2.5411e-06\n",
      "Epoch 9/100\n",
      "315/315 [==============================] - 1s 4ms/step - loss: 0.0759 - MSE: 2.4306e-06 - val_loss: 0.1176 - val_MSE: 4.5217e-06\n",
      "Epoch 10/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0961 - MSE: 2.8294e-06 - val_loss: 0.0721 - val_MSE: 2.5230e-06\n",
      "Epoch 11/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0747 - MSE: 2.3675e-06 - val_loss: 0.0771 - val_MSE: 2.8219e-06\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 12/100\n",
      "315/315 [==============================] - 1s 5ms/step - loss: 0.0661 - MSE: 2.4133e-06 - val_loss: 0.0651 - val_MSE: 2.3228e-06\n",
      "Epoch 13/100\n",
      "315/315 [==============================] - 2s 6ms/step - loss: 0.0649 - MSE: 2.3146e-06 - val_loss: 0.0656 - val_MSE: 2.3293e-06\n",
      "Epoch 14/100\n",
      "315/315 [==============================] - 2s 5ms/step - loss: 0.0640 - MSE: 2.4182e-06 - val_loss: 0.0657 - val_MSE: 2.3926e-06\n",
      "Epoch 15/100\n",
      "315/315 [==============================] - 1s 5ms/step - loss: 0.0653 - MSE: 2.3181e-06 - val_loss: 0.0655 - val_MSE: 2.3297e-06\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 16/100\n",
      "315/315 [==============================] - 2s 6ms/step - loss: 0.0635 - MSE: 2.2897e-06 - val_loss: 0.0647 - val_MSE: 2.3536e-06\n",
      "Epoch 17/100\n",
      "315/315 [==============================] - 1s 4ms/step - loss: 0.0624 - MSE: 2.2982e-06 - val_loss: 0.0648 - val_MSE: 2.4000e-06\n",
      "Epoch 18/100\n",
      "315/315 [==============================] - 2s 5ms/step - loss: 0.0625 - MSE: 2.3097e-06 - val_loss: 0.0654 - val_MSE: 2.3271e-06\n",
      "Epoch 19/100\n",
      "315/315 [==============================] - 2s 5ms/step - loss: 0.0626 - MSE: 2.3056e-06 - val_loss: 0.0645 - val_MSE: 2.3442e-06\n",
      "Epoch 20/100\n",
      "315/315 [==============================] - 2s 6ms/step - loss: 0.0641 - MSE: 2.3005e-06 - val_loss: 0.0644 - val_MSE: 2.3330e-06\n",
      "Epoch 21/100\n",
      "315/315 [==============================] - 1s 4ms/step - loss: 0.0628 - MSE: 2.3521e-06 - val_loss: 0.0640 - val_MSE: 2.3586e-06\n",
      "Epoch 22/100\n",
      "315/315 [==============================] - 2s 6ms/step - loss: 0.0639 - MSE: 2.3421e-06 - val_loss: 0.0668 - val_MSE: 2.5086e-06\n",
      "Epoch 23/100\n",
      "315/315 [==============================] - 1s 4ms/step - loss: 0.0633 - MSE: 2.3504e-06 - val_loss: 0.0650 - val_MSE: 2.3543e-06\n",
      "Epoch 24/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0631 - MSE: 2.3605e-06 - val_loss: 0.0664 - val_MSE: 2.3367e-06\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 25/100\n",
      "315/315 [==============================] - 1s 5ms/step - loss: 0.0620 - MSE: 2.3763e-06 - val_loss: 0.0643 - val_MSE: 2.3912e-06\n",
      "Epoch 26/100\n",
      "315/315 [==============================] - 2s 6ms/step - loss: 0.0625 - MSE: 2.3296e-06 - val_loss: 0.0644 - val_MSE: 2.3586e-06\n",
      "Epoch 27/100\n",
      "315/315 [==============================] - 2s 6ms/step - loss: 0.0622 - MSE: 2.3301e-06 - val_loss: 0.0644 - val_MSE: 2.3789e-06\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Epoch 28/100\n",
      "315/315 [==============================] - 2s 5ms/step - loss: 0.0618 - MSE: 2.3274e-06 - val_loss: 0.0643 - val_MSE: 2.3756e-06\n",
      "Epoch 29/100\n",
      "315/315 [==============================] - 2s 5ms/step - loss: 0.0629 - MSE: 2.3544e-06 - val_loss: 0.0643 - val_MSE: 2.3615e-06\n",
      "Epoch 30/100\n",
      "315/315 [==============================] - 1s 5ms/step - loss: 0.0621 - MSE: 2.2964e-06 - val_loss: 0.0644 - val_MSE: 2.3871e-06\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.199999628122896e-06.\n",
      "Epoch 31/100\n",
      "315/315 [==============================] - 1s 5ms/step - loss: 0.0621 - MSE: 2.3528e-06 - val_loss: 0.0643 - val_MSE: 2.3787e-06\n",
      "Epoch 00031: early stopping\n",
      "Fold 2 NN: 0.25364\n",
      "CV 3/4\n",
      "Epoch 1/100\n",
      "315/315 [==============================] - 14s 44ms/step - loss: 1552.1466 - MSE: 0.0068 - val_loss: 1.1436 - val_MSE: 1.2587e-05\n",
      "Epoch 2/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 4.3544 - MSE: 9.1577e-06 - val_loss: 0.1290 - val_MSE: 5.5223e-06\n",
      "Epoch 3/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.1319 - MSE: 5.3913e-06 - val_loss: 0.1292 - val_MSE: 4.6494e-06\n",
      "Epoch 4/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.1104 - MSE: 4.2778e-06 - val_loss: 0.0891 - val_MSE: 3.7089e-06\n",
      "Epoch 5/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0956 - MSE: 3.3835e-06 - val_loss: 0.0781 - val_MSE: 2.9469e-06\n",
      "Epoch 6/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0823 - MSE: 2.8747e-06 - val_loss: 0.0720 - val_MSE: 2.5529e-06\n",
      "Epoch 7/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.1039 - MSE: 2.6632e-06 - val_loss: 0.0747 - val_MSE: 2.4492e-06\n",
      "Epoch 8/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0993 - MSE: 2.5354e-06 - val_loss: 0.9087 - val_MSE: 5.7346e-06\n",
      "Epoch 9/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.3034 - MSE: 3.6280e-06 - val_loss: 0.1126 - val_MSE: 2.9664e-06\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 10/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0791 - MSE: 2.5864e-06 - val_loss: 0.0717 - val_MSE: 2.4244e-06\n",
      "Epoch 11/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0746 - MSE: 2.5001e-06 - val_loss: 0.0691 - val_MSE: 2.4390e-06\n",
      "Epoch 12/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0722 - MSE: 2.4514e-06 - val_loss: 0.0851 - val_MSE: 2.4310e-06\n",
      "Epoch 13/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0727 - MSE: 2.3777e-06 - val_loss: 0.0693 - val_MSE: 2.3543e-06\n",
      "Epoch 14/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0727 - MSE: 2.3486e-06 - val_loss: 0.0726 - val_MSE: 2.4957e-06\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 15/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0700 - MSE: 2.3412e-06 - val_loss: 0.0675 - val_MSE: 2.2835e-06\n",
      "Epoch 16/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0701 - MSE: 2.3703e-06 - val_loss: 0.0675 - val_MSE: 2.2802e-06\n",
      "Epoch 17/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0711 - MSE: 2.3828e-06 - val_loss: 0.0672 - val_MSE: 2.2876e-06\n",
      "Epoch 18/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0700 - MSE: 2.3722e-06 - val_loss: 0.0675 - val_MSE: 2.3166e-06\n",
      "Epoch 19/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0739 - MSE: 2.3307e-06 - val_loss: 0.0679 - val_MSE: 2.2805e-06\n",
      "Epoch 20/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0694 - MSE: 2.3566e-06 - val_loss: 0.0693 - val_MSE: 2.2123e-06\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 21/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0679 - MSE: 2.3273e-06 - val_loss: 0.0668 - val_MSE: 2.2716e-06\n",
      "Epoch 22/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0685 - MSE: 2.2949e-06 - val_loss: 0.0664 - val_MSE: 2.3045e-06\n",
      "Epoch 23/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0670 - MSE: 2.3088e-06 - val_loss: 0.0670 - val_MSE: 2.2653e-06\n",
      "Epoch 24/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0685 - MSE: 2.3061e-06 - val_loss: 0.0672 - val_MSE: 2.2759e-06\n",
      "Epoch 25/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0686 - MSE: 2.2958e-06 - val_loss: 0.0665 - val_MSE: 2.2829e-06\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Epoch 26/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0666 - MSE: 2.3452e-06 - val_loss: 0.0666 - val_MSE: 2.2741e-06\n",
      "Epoch 27/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0660 - MSE: 2.2834e-06 - val_loss: 0.0663 - val_MSE: 2.2887e-06\n",
      "Epoch 28/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0682 - MSE: 2.3177e-06 - val_loss: 0.0668 - val_MSE: 2.2809e-06\n",
      "Epoch 29/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0666 - MSE: 2.3001e-06 - val_loss: 0.0667 - val_MSE: 2.2604e-06\n",
      "Epoch 30/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0663 - MSE: 2.2852e-06 - val_loss: 0.0663 - val_MSE: 2.3036e-06\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 3.199999628122896e-06.\n",
      "Epoch 31/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0669 - MSE: 2.3270e-06 - val_loss: 0.0662 - val_MSE: 2.2743e-06\n",
      "Epoch 32/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0661 - MSE: 2.3276e-06 - val_loss: 0.0665 - val_MSE: 2.2789e-06\n",
      "Epoch 33/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0661 - MSE: 2.3228e-06 - val_loss: 0.0662 - val_MSE: 2.2739e-06\n",
      "Epoch 34/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0693 - MSE: 2.2889e-06 - val_loss: 0.0663 - val_MSE: 2.2931e-06\n",
      "Epoch 35/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0686 - MSE: 2.3027e-06 - val_loss: 0.0662 - val_MSE: 2.2750e-06\n",
      "Epoch 36/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0674 - MSE: 2.2883e-06 - val_loss: 0.0662 - val_MSE: 2.2762e-06\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 6.399999165296323e-07.\n",
      "Epoch 37/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0666 - MSE: 2.3030e-06 - val_loss: 0.0661 - val_MSE: 2.2828e-06\n",
      "Epoch 38/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0671 - MSE: 2.3138e-06 - val_loss: 0.0662 - val_MSE: 2.2730e-06\n",
      "Epoch 39/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0656 - MSE: 2.2804e-06 - val_loss: 0.0661 - val_MSE: 2.2842e-06\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.2799998785339995e-07.\n",
      "Epoch 40/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0659 - MSE: 2.3217e-06 - val_loss: 0.0661 - val_MSE: 2.2809e-06\n",
      "Epoch 41/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0666 - MSE: 2.3162e-06 - val_loss: 0.0661 - val_MSE: 2.2782e-06\n",
      "Epoch 42/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0675 - MSE: 2.3036e-06 - val_loss: 0.0662 - val_MSE: 2.2769e-06\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 2.5599996433811613e-08.\n",
      "Epoch 43/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0663 - MSE: 2.2595e-06 - val_loss: 0.0661 - val_MSE: 2.2789e-06\n",
      "Epoch 44/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0674 - MSE: 2.2750e-06 - val_loss: 0.0661 - val_MSE: 2.2793e-06\n",
      "Epoch 45/100\n",
      "315/315 [==============================] - 1s 4ms/step - loss: 0.0656 - MSE: 2.3609e-06 - val_loss: 0.0661 - val_MSE: 2.2803e-06\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 5.1199993578165965e-09.\n",
      "Epoch 46/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0685 - MSE: 2.3161e-06 - val_loss: 0.0661 - val_MSE: 2.2803e-06\n",
      "Epoch 47/100\n",
      "315/315 [==============================] - 1s 4ms/step - loss: 0.0665 - MSE: 2.3290e-06 - val_loss: 0.0661 - val_MSE: 2.2803e-06\n",
      "Epoch 00047: early stopping\n",
      "Fold 3 NN: 0.25718\n",
      "CV 4/4\n",
      "Epoch 1/100\n",
      "315/315 [==============================] - 14s 43ms/step - loss: 1752.1038 - MSE: 0.0083 - val_loss: 0.6397 - val_MSE: 1.6589e-05\n",
      "Epoch 2/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.6314 - MSE: 1.5151e-05 - val_loss: 0.2716 - val_MSE: 1.1714e-05\n",
      "Epoch 3/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.2420 - MSE: 1.0566e-05 - val_loss: 0.1835 - val_MSE: 7.8819e-06\n",
      "Epoch 4/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.1773 - MSE: 7.3196e-06 - val_loss: 0.1389 - val_MSE: 5.2027e-06\n",
      "Epoch 5/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.1285 - MSE: 5.0566e-06 - val_loss: 0.1004 - val_MSE: 3.6540e-06\n",
      "Epoch 6/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.1347 - MSE: 3.7266e-06 - val_loss: 0.9499 - val_MSE: 4.3650e-06\n",
      "Epoch 7/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.1574 - MSE: 3.2037e-06 - val_loss: 0.4315 - val_MSE: 2.9741e-06\n",
      "Epoch 8/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.1373 - MSE: 2.8216e-06 - val_loss: 0.1583 - val_MSE: 2.9020e-06\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 9/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0825 - MSE: 2.4258e-06 - val_loss: 0.0779 - val_MSE: 2.3005e-06\n",
      "Epoch 10/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0756 - MSE: 2.4321e-06 - val_loss: 0.0739 - val_MSE: 2.4011e-06\n",
      "Epoch 11/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0720 - MSE: 2.3626e-06 - val_loss: 0.0787 - val_MSE: 2.5275e-06\n",
      "Epoch 12/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0845 - MSE: 2.4009e-06 - val_loss: 0.0710 - val_MSE: 2.3724e-06\n",
      "Epoch 13/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0786 - MSE: 2.3325e-06 - val_loss: 0.0710 - val_MSE: 2.3017e-06\n",
      "Epoch 14/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0810 - MSE: 2.3616e-06 - val_loss: 0.1388 - val_MSE: 3.0024e-06\n",
      "Epoch 15/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0923 - MSE: 2.4328e-06 - val_loss: 0.0718 - val_MSE: 2.3182e-06\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 16/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.1577 - MSE: 2.3680e-06 - val_loss: 0.0693 - val_MSE: 2.3317e-06\n",
      "Epoch 17/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0770 - MSE: 2.2499e-06 - val_loss: 0.0696 - val_MSE: 2.3376e-06\n",
      "Epoch 18/100\n",
      "315/315 [==============================] - 1s 4ms/step - loss: 0.0766 - MSE: 2.2803e-06 - val_loss: 0.0691 - val_MSE: 2.2771e-06\n",
      "Epoch 19/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0740 - MSE: 2.2886e-06 - val_loss: 0.0697 - val_MSE: 2.2857e-06\n",
      "Epoch 20/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0724 - MSE: 2.2424e-06 - val_loss: 0.0729 - val_MSE: 2.4154e-06\n",
      "Epoch 21/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0708 - MSE: 2.2780e-06 - val_loss: 0.0933 - val_MSE: 2.2518e-06\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 22/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0770 - MSE: 2.2840e-06 - val_loss: 0.0695 - val_MSE: 2.3051e-06\n",
      "Epoch 23/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0700 - MSE: 2.2427e-06 - val_loss: 0.0687 - val_MSE: 2.3216e-06\n",
      "Epoch 24/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0690 - MSE: 2.2666e-06 - val_loss: 0.0701 - val_MSE: 2.3514e-06\n",
      "Epoch 25/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0697 - MSE: 2.2684e-06 - val_loss: 0.0700 - val_MSE: 2.2647e-06\n",
      "Epoch 26/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0719 - MSE: 2.2561e-06 - val_loss: 0.0739 - val_MSE: 2.4630e-06\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Epoch 27/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0688 - MSE: 2.2429e-06 - val_loss: 0.0703 - val_MSE: 2.3422e-06\n",
      "Epoch 28/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0691 - MSE: 2.2586e-06 - val_loss: 0.0684 - val_MSE: 2.2987e-06\n",
      "Epoch 29/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0697 - MSE: 2.2401e-06 - val_loss: 0.0687 - val_MSE: 2.2814e-06\n",
      "Epoch 30/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0688 - MSE: 2.2442e-06 - val_loss: 0.0701 - val_MSE: 2.2861e-06\n",
      "Epoch 31/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0720 - MSE: 2.2433e-06 - val_loss: 0.0690 - val_MSE: 2.2725e-06\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 3.199999628122896e-06.\n",
      "Epoch 32/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0695 - MSE: 2.2759e-06 - val_loss: 0.0684 - val_MSE: 2.3035e-06\n",
      "Epoch 33/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0683 - MSE: 2.2247e-06 - val_loss: 0.0684 - val_MSE: 2.3011e-06\n",
      "Epoch 34/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0687 - MSE: 2.2433e-06 - val_loss: 0.0694 - val_MSE: 2.3589e-06\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 6.399999165296323e-07.\n",
      "Epoch 35/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0699 - MSE: 2.3186e-06 - val_loss: 0.0684 - val_MSE: 2.2894e-06\n",
      "Epoch 36/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0678 - MSE: 2.2500e-06 - val_loss: 0.0686 - val_MSE: 2.3095e-06\n",
      "Epoch 37/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0693 - MSE: 2.2448e-06 - val_loss: 0.0684 - val_MSE: 2.3004e-06\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.2799998785339995e-07.\n",
      "Epoch 38/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0692 - MSE: 2.2404e-06 - val_loss: 0.0684 - val_MSE: 2.2953e-06\n",
      "Epoch 39/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0700 - MSE: 2.2406e-06 - val_loss: 0.0684 - val_MSE: 2.2898e-06\n",
      "Epoch 40/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0677 - MSE: 2.2158e-06 - val_loss: 0.0684 - val_MSE: 2.3020e-06\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.5599996433811613e-08.\n",
      "Epoch 41/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0712 - MSE: 2.2318e-06 - val_loss: 0.0684 - val_MSE: 2.2972e-06\n",
      "Epoch 42/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0680 - MSE: 2.2821e-06 - val_loss: 0.0684 - val_MSE: 2.2977e-06\n",
      "Epoch 43/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0691 - MSE: 2.3001e-06 - val_loss: 0.0684 - val_MSE: 2.2972e-06\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 5.1199993578165965e-09.\n",
      "Epoch 44/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0682 - MSE: 2.2220e-06 - val_loss: 0.0684 - val_MSE: 2.2974e-06\n",
      "Epoch 45/100\n",
      "315/315 [==============================] - 1s 3ms/step - loss: 0.0684 - MSE: 2.2514e-06 - val_loss: 0.0684 - val_MSE: 2.2976e-06\n",
      "Epoch 00045: early stopping\n",
      "Fold 4 NN: 0.26156\n"
     ]
    }
   ],
   "source": [
    "model_name = 'NN'\n",
    "pred_name = 'pred_{}'.format(model_name)\n",
    "\n",
    "n_folds = 4\n",
    "kf = model_selection.KFold(n_splits=n_folds, shuffle=True, random_state=2020)\n",
    "scores_folds[model_name] = []\n",
    "counter = 1\n",
    "\n",
    "features_to_consider = ['stock_id','log_return1','log_return2','trade_log_return1']\n",
    "\n",
    "train[pred_name] = 0\n",
    "test['target'] = 0\n",
    "\n",
    "for dev_index, val_index in kf.split(range(len(train))):\n",
    "    print('CV {}/{}'.format(counter, n_folds))\n",
    "    \n",
    "    #Bottleneck ? \n",
    "    X_train = train.loc[dev_index, features_to_consider]\n",
    "    y_train = train.loc[dev_index, target_name].values\n",
    "    X_test = train.loc[val_index, features_to_consider]\n",
    "    y_test = train.loc[val_index, target_name].values\n",
    "    \n",
    "    #############################################################################################\n",
    "    # NN\n",
    "    #############################################################################################\n",
    "    \n",
    "    model = base_model()\n",
    "    \n",
    "    model.compile(\n",
    "        keras.optimizers.Adam(learning_rate=0.01),\n",
    "        loss=tf.keras.metrics.mean_squared_error,\n",
    "        metrics=['MSE'],\n",
    "    )\n",
    "\n",
    "\n",
    "    num_data = X_train[['log_return1','log_return2','trade_log_return1']]\n",
    "    cat_data = X_train['stock_id']\n",
    "    target =  y_train\n",
    "    \n",
    "    num_data_test = X_test[['log_return1','log_return2','trade_log_return1']]\n",
    "    cat_data_test = X_test['stock_id']\n",
    "\n",
    "    model.fit([cat_data, num_data], \n",
    "              target, \n",
    "              sample_weight = 1/np.square(target),\n",
    "              batch_size=1024,\n",
    "              epochs=100,\n",
    "              validation_data=([cat_data_test, num_data_test], y_test, 1/np.square(y_test)),\n",
    "              callbacks=[es, plateau],\n",
    "              shuffle=True,\n",
    "             verbose = 1)\n",
    "\n",
    "    preds = model.predict([cat_data_test, num_data_test]).reshape(1,-1)[0]\n",
    "    \n",
    "    score = round(rmspe(y_true = y_test, y_pred = preds),5)\n",
    "    print('Fold {} {}: {}'.format(counter, model_name, score))\n",
    "    scores_folds[model_name].append(score)\n",
    "    test[target_name] += model.predict([test['stock_id'], test[['log_return1','log_return2','trade_log_return1']]]).reshape(1,-1)[0].clip(0,1e10)\n",
    "       \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "chinese-pittsburgh",
   "metadata": {
    "papermill": {
     "duration": 0.995253,
     "end_time": "2021-07-23T19:23:46.518964",
     "exception": false,
     "start_time": "2021-07-23T19:23:45.523711",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSPE NN: 1.0 - Folds: [0.25463, 0.25364, 0.25718, 0.26156]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-4</td>\n",
       "      <td>0.000561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-32</td>\n",
       "      <td>0.000391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  row_id    target\n",
       "0    0-4  0.000561\n",
       "1   0-32  0.000391"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "test[target_name] = test[target_name]/n_folds\n",
    "\n",
    "score = round(rmspe(y_true = train[target_name].values, y_pred = train[pred_name].values),5)\n",
    "print('RMSPE {}: {} - Folds: {}'.format(model_name, score, scores_folds[model_name]))\n",
    "\n",
    "display(test[['row_id', target_name]].head(2))\n",
    "test[['row_id', target_name]].to_csv('submission.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-subcommittee",
   "metadata": {
    "papermill": {
     "duration": 0.938436,
     "end_time": "2021-07-23T19:23:48.390292",
     "exception": false,
     "start_time": "2021-07-23T19:23:47.451856",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant-course",
   "language": "python",
   "name": "quant-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 849.359895,
   "end_time": "2021-07-23T19:23:51.168832",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-23T19:09:41.808937",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
