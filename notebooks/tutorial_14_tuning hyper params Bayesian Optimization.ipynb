{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition - Quant & Machine Learning Course\n",
    "# Tutorial 14: Bayesian Optimization for Hyper-parameter Tuning\n",
    "\n",
    "Modified based on resource https://www.kaggle.com/somang1418/tuning-hyperparameters-under-10-minutes-lgbm/data?select=train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b387c0ff9fb2ade4c5365c6bc02c8ef96d515b9f"
   },
   "source": [
    "**Bayesian Optimization** is a probabilistic model based approach for finding the minimum of any function that returns a real-value metric. [(source)](https://towardsdatascience.com/an-introductory-example-of-bayesian-optimization-in-python-with-hyperopt-aae40fff4ff0)<br> It is very effective with real-world applications in high-dimensional parameter-tuning for complex machine learning algorithms. Bayesian optimization utilizes the Bayesian technique of setting a prior over the objective function and\n",
    "combining it with evidence to get a posterior function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "44e3d052e7977441be8ce913532021d36e902884"
   },
   "source": [
    "\n",
    "## Loading Library and Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "#basic tools \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "#tuning hyperparameters\n",
    "from bayes_opt import BayesianOptimization\n",
    "from skopt  import BayesSearchCV \n",
    "\n",
    "#graph, plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#building models\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "import time\n",
    "import sys\n",
    "\n",
    "#metrics \n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import shap\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "de9279f02cb62dab5f485b915225730f2e0177f7"
   },
   "source": [
    "By Changing the data type of each column, I reduced memory usages by 75%. By taking the minimum and the maximum of each column, the function assigns which numeric data type is optimal for the column and change the data type. If you want to know more about how it works, I suggest you to read [Eryk's article](https://towardsdatascience.com/make-working-with-large-dataframes-easier-at-least-for-your-memory-6f52b5f4b5c4)! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "bfb1d1eac5f3a3bf038a87f898554a24dc2ea701"
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 78.01 Mb (74.7% reduction)\n",
      "Mem. usage decreased to 77.82 Mb (74.6% reduction)\n",
      "Shape of train set:  (200000, 202)\n",
      "Shape of test set:  (200000, 201)\n",
      "CPU times: user 40.3 s, sys: 26 s, total: 1min 6s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train= reduce_mem_usage(pd.read_csv(\"~/Documents/deep-learning/quant_course/data/sales_prediction_train.csv\"))\n",
    "test= reduce_mem_usage(pd.read_csv(\"~/Documents/deep-learning/quant_course/data/sales_prediction_test.csv\"))\n",
    "print(\"Shape of train set: \",train.shape)\n",
    "print(\"Shape of test set: \",test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a9ec6cc2927deaa05c78c3d6f88bb8e7991b20ff"
   },
   "source": [
    "\n",
    "## Bayesian Optimization with LightGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "eed38f9174e3bb4e2d24b5e9cebde198be946826"
   },
   "outputs": [],
   "source": [
    "y=train['target']\n",
    "X=train.drop(['ID_code','target'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.921875</td>\n",
       "      <td>-6.785156</td>\n",
       "      <td>11.906250</td>\n",
       "      <td>5.093750</td>\n",
       "      <td>11.460938</td>\n",
       "      <td>-9.281250</td>\n",
       "      <td>5.117188</td>\n",
       "      <td>18.625000</td>\n",
       "      <td>-4.921875</td>\n",
       "      <td>5.746094</td>\n",
       "      <td>...</td>\n",
       "      <td>4.433594</td>\n",
       "      <td>3.964844</td>\n",
       "      <td>3.136719</td>\n",
       "      <td>1.691406</td>\n",
       "      <td>18.515625</td>\n",
       "      <td>-2.398438</td>\n",
       "      <td>7.878906</td>\n",
       "      <td>8.562500</td>\n",
       "      <td>12.781250</td>\n",
       "      <td>-1.091797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.500000</td>\n",
       "      <td>-4.148438</td>\n",
       "      <td>13.859375</td>\n",
       "      <td>5.390625</td>\n",
       "      <td>12.359375</td>\n",
       "      <td>7.042969</td>\n",
       "      <td>5.621094</td>\n",
       "      <td>16.531250</td>\n",
       "      <td>3.146484</td>\n",
       "      <td>8.085938</td>\n",
       "      <td>...</td>\n",
       "      <td>7.640625</td>\n",
       "      <td>7.722656</td>\n",
       "      <td>2.583984</td>\n",
       "      <td>10.953125</td>\n",
       "      <td>15.429688</td>\n",
       "      <td>2.033203</td>\n",
       "      <td>8.125000</td>\n",
       "      <td>8.789062</td>\n",
       "      <td>18.359375</td>\n",
       "      <td>1.952148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.609375</td>\n",
       "      <td>-2.746094</td>\n",
       "      <td>12.078125</td>\n",
       "      <td>7.894531</td>\n",
       "      <td>10.585938</td>\n",
       "      <td>-9.085938</td>\n",
       "      <td>6.941406</td>\n",
       "      <td>14.617188</td>\n",
       "      <td>-4.917969</td>\n",
       "      <td>5.953125</td>\n",
       "      <td>...</td>\n",
       "      <td>2.906250</td>\n",
       "      <td>9.789062</td>\n",
       "      <td>1.669922</td>\n",
       "      <td>1.685547</td>\n",
       "      <td>21.609375</td>\n",
       "      <td>3.142578</td>\n",
       "      <td>-6.519531</td>\n",
       "      <td>8.265625</td>\n",
       "      <td>14.718750</td>\n",
       "      <td>0.396484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.062500</td>\n",
       "      <td>-2.152344</td>\n",
       "      <td>8.953125</td>\n",
       "      <td>7.195312</td>\n",
       "      <td>12.585938</td>\n",
       "      <td>-1.835938</td>\n",
       "      <td>5.843750</td>\n",
       "      <td>14.921875</td>\n",
       "      <td>-5.859375</td>\n",
       "      <td>8.242188</td>\n",
       "      <td>...</td>\n",
       "      <td>4.464844</td>\n",
       "      <td>4.742188</td>\n",
       "      <td>0.717773</td>\n",
       "      <td>1.421875</td>\n",
       "      <td>23.031250</td>\n",
       "      <td>-1.270508</td>\n",
       "      <td>-2.927734</td>\n",
       "      <td>10.289062</td>\n",
       "      <td>17.968750</td>\n",
       "      <td>-9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.835938</td>\n",
       "      <td>-1.483398</td>\n",
       "      <td>12.875000</td>\n",
       "      <td>6.636719</td>\n",
       "      <td>12.273438</td>\n",
       "      <td>2.449219</td>\n",
       "      <td>5.941406</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>6.265625</td>\n",
       "      <td>7.679688</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.490234</td>\n",
       "      <td>9.523438</td>\n",
       "      <td>-0.150757</td>\n",
       "      <td>9.195312</td>\n",
       "      <td>13.289062</td>\n",
       "      <td>-1.511719</td>\n",
       "      <td>3.925781</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>-8.812500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var_0     var_1      var_2     var_3      var_4     var_5     var_6  \\\n",
       "0   8.921875 -6.785156  11.906250  5.093750  11.460938 -9.281250  5.117188   \n",
       "1  11.500000 -4.148438  13.859375  5.390625  12.359375  7.042969  5.621094   \n",
       "2   8.609375 -2.746094  12.078125  7.894531  10.585938 -9.085938  6.941406   \n",
       "3  11.062500 -2.152344   8.953125  7.195312  12.585938 -1.835938  5.843750   \n",
       "4   9.835938 -1.483398  12.875000  6.636719  12.273438  2.449219  5.941406   \n",
       "\n",
       "       var_7     var_8     var_9  ...   var_190   var_191   var_192  \\\n",
       "0  18.625000 -4.921875  5.746094  ...  4.433594  3.964844  3.136719   \n",
       "1  16.531250  3.146484  8.085938  ...  7.640625  7.722656  2.583984   \n",
       "2  14.617188 -4.917969  5.953125  ...  2.906250  9.789062  1.669922   \n",
       "3  14.921875 -5.859375  8.242188  ...  4.464844  4.742188  0.717773   \n",
       "4  19.250000  6.265625  7.679688  ... -1.490234  9.523438 -0.150757   \n",
       "\n",
       "     var_193    var_194   var_195   var_196    var_197    var_198   var_199  \n",
       "0   1.691406  18.515625 -2.398438  7.878906   8.562500  12.781250 -1.091797  \n",
       "1  10.953125  15.429688  2.033203  8.125000   8.789062  18.359375  1.952148  \n",
       "2   1.685547  21.609375  3.142578 -6.519531   8.265625  14.718750  0.396484  \n",
       "3   1.421875  23.031250 -1.270508 -2.927734  10.289062  17.968750 -9.000000  \n",
       "4   9.195312  13.289062 -1.511719  3.925781   9.500000  18.000000 -8.812500  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20098"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "843ef1318ddeef62fca96228baf9c188355adc42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27 µs, sys: 85 µs, total: 112 µs\n",
      "Wall time: 126 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def bayes_parameter_opt_lgb(X, y, init_round=15, opt_round=25, n_folds=3, random_seed=6,n_estimators=10000, output_process=False):\n",
    "    # prepare data\n",
    "    train_data = lgb.Dataset(data=X, label=y, free_raw_data=False)\n",
    "    # parameters\n",
    "    def lgb_eval(learning_rate,num_leaves, feature_fraction, bagging_fraction, max_depth, max_bin, min_data_in_leaf,min_sum_hessian_in_leaf,subsample):\n",
    "        params = {'application':'binary', 'metric':'auc'}\n",
    "        params['learning_rate'] = max(min(learning_rate, 1), 0)\n",
    "        params[\"num_leaves\"] = int(round(num_leaves))\n",
    "        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "        params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "        params['max_depth'] = int(round(max_depth))\n",
    "        params['max_bin'] = int(round(max_depth))\n",
    "        params['min_data_in_leaf'] = int(round(min_data_in_leaf))\n",
    "        params['min_sum_hessian_in_leaf'] = min_sum_hessian_in_leaf\n",
    "        params['subsample'] = max(min(subsample, 1), 0)\n",
    "        \n",
    "        cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval =200, metrics=['auc'])\n",
    "        return max(cv_result['auc-mean'])\n",
    "     \n",
    "    lgbBO = BayesianOptimization(lgb_eval, {'learning_rate': (0.01, 1.0),\n",
    "                                            'num_leaves': (24, 80),\n",
    "                                            'feature_fraction': (0.1, 0.9),\n",
    "                                            'bagging_fraction': (0.8, 1),\n",
    "                                            'max_depth': (5, 30),\n",
    "                                            'max_bin':(20,90),\n",
    "                                            'min_data_in_leaf': (20, 80),\n",
    "                                            'min_sum_hessian_in_leaf':(0,100),\n",
    "                                           'subsample': (0.01, 1.0)}, random_state=200)\n",
    "\n",
    "    \n",
    "    #n_iter: How many steps of bayesian optimization you want to perform. The more steps the more likely to find a good maximum you are.\n",
    "    #init_points: How many steps of random exploration you want to perform. Random exploration can help by diversifying the exploration space.\n",
    "    \n",
    "    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n",
    "    \n",
    "    model_auc=[]\n",
    "    for model in range(len( lgbBO.res)):\n",
    "        model_auc.append(lgbBO.res[model]['target'])\n",
    "    \n",
    "    # return best parameters\n",
    "    return lgbBO.res[pd.Series(model_auc).idxmax()]['target'],lgbBO.res[pd.Series(model_auc).idxmax()]['params']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params = bayes_parameter_opt_lgb(X, y, init_round=5, opt_round=10, n_folds=3, random_seed=6,n_estimators=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e3928f65a0c13a36fcdfbc6a5ee97c94d3657649"
   },
   "source": [
    "Here is my optimal parameter for LightGBM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "c87ba1a969f21ff1fd5057642f820149e3ac3cec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.8587937033434263,\n",
       " 'feature_fraction': 0.17035409528632064,\n",
       " 'learning_rate': 0.20242837470652494,\n",
       " 'max_bin': 74,\n",
       " 'max_depth': 25,\n",
       " 'min_data_in_leaf': 39,\n",
       " 'min_sum_hessian_in_leaf': 13.471651529525241,\n",
       " 'num_leaves': 27,\n",
       " 'subsample': 0.7751907561797581,\n",
       " 'objective': 'binary',\n",
       " 'metric': 'auc',\n",
       " 'is_unbalance': True,\n",
       " 'boost_from_average': False}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt_params[1][\"num_leaves\"] = int(round(opt_params[1][\"num_leaves\"]))\n",
    "opt_params[1]['max_depth'] = int(round(opt_params[1]['max_depth']))\n",
    "opt_params[1]['min_data_in_leaf'] = int(round(opt_params[1]['min_data_in_leaf']))\n",
    "opt_params[1]['max_bin'] = int(round(opt_params[1]['max_bin']))\n",
    "opt_params[1]['objective']='binary'\n",
    "opt_params[1]['metric']='auc'\n",
    "opt_params[1]['is_unbalance']=True\n",
    "opt_params[1]['boost_from_average']=False\n",
    "opt_params=opt_params[1]\n",
    "opt_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "2c5b897ac3c6675ea104393aabec929da5ef4d97"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant-course",
   "language": "python",
   "name": "quant-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
