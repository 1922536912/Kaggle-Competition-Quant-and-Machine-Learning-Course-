{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "070f97b6-7c4b-420b-a5f8-ed2eb0663544",
   "metadata": {},
   "source": [
    "# Kaggle Competition - Quant & Machine Learning Course\n",
    "# Tutorial 10: Deep NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bd1fafe-3125-48ba-9ca4-377a83778d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
      "57344/57026 [==============================] - 0s 1us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-30 21:37:41.766097: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-08-30 21:37:41.959092: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 1s 2ms/step - loss: 472.1914 - mse: 472.1914\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 122.0721 - mse: 122.0722\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 89.0634 - mse: 89.0634\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 82.1549 - mse: 82.1549\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 91.8302 - mse: 91.8302\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 88.6728 - mse: 88.6728\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 91.4876 - mse: 91.4876\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 90.0732 - mse: 90.0732\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.7826 - mse: 84.7826\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 88.8424 - mse: 88.8424\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 83.4814 - mse: 83.4814\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 78.0864 - mse: 78.0864\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 82.8693 - mse: 82.8693\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 78.6253 - mse: 78.6253\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 80.9591 - mse: 80.9591\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 88.1512 - mse: 88.1512\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 85.8370 - mse: 85.8370\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 86.4665 - mse: 86.4665\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 63.5334 - mse: 63.5334\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 74.4584 - mse: 74.4584\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 73.7151 - mse: 73.7151\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 66.2650 - mse: 66.2650\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 70.1570 - mse: 70.1570\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 78.5684 - mse: 78.5684\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 72.3423 - mse: 72.3423\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 81.0756 - mse: 81.0756\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 73.6420 - mse: 73.6420\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 83.1597 - mse: 83.1597\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 81.2477 - mse: 81.2477\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 87.1494 - mse: 87.1494\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 88.6385 - mse: 88.6385\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 73.7524 - mse: 73.7524\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 90.7860 - mse: 90.7860\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 74.1414 - mse: 74.1414\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 83.3660 - mse: 83.3660\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 82.3144 - mse: 82.3144\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 72.7342 - mse: 72.7342\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 81.5215 - mse: 81.5215\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 93.1238 - mse: 93.1238\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 69.7174 - mse: 69.7174\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 76.8128 - mse: 76.8128\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 79.1199 - mse: 79.1199\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 82.4553 - mse: 82.4553\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 79.4372 - mse: 79.4372\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 90.4321 - mse: 90.4321\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 73.1525 - mse: 73.1525\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 71.9949 - mse: 71.9949\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 79.5835 - mse: 79.5835\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 79.9748 - mse: 79.9748\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 81.2505 - mse: 81.2505\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 73.4922 - mse: 73.4922\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 70.5245 - mse: 70.5245\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 80.2443 - mse: 80.2443\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 74.3579 - mse: 74.3579\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 74.8313 - mse: 74.8313\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 72.9542 - mse: 72.9542\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 76.2109 - mse: 76.2109\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 79.9127 - mse: 79.9127\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 80.7606 - mse: 80.7606\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 73.7926 - mse: 73.7926\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 72.1696 - mse: 72.1696\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 86.3989 - mse: 86.3989\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 76.2387 - mse: 76.2387\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 71.1407 - mse: 71.1407\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 94.3929 - mse: 94.3929\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 77.8443 - mse: 77.8443\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 81.4663 - mse: 81.4663\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 74.8131 - mse: 74.8131\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 90.8197 - mse: 90.8197\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 87.6029 - mse: 87.6029\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 76.8149 - mse: 76.8149\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 80.5590 - mse: 80.5590\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 78.7082 - mse: 78.7082\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 70.9759 - mse: 70.9759\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 78.9248 - mse: 78.9248\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 72.2181 - mse: 72.2181\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 72.6512 - mse: 72.6512\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 75.6723 - mse: 75.6723\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 81.3344 - mse: 81.3344\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 71.7152 - mse: 71.7152\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 78.9633 - mse: 78.9633\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 72.4382 - mse: 72.4382\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 81.3918 - mse: 81.3918\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 72.3838 - mse: 72.3838\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 70.8379 - mse: 70.8379\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 74.8122 - mse: 74.8122\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 72.1356 - mse: 72.1356\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 91.5361 - mse: 91.5361\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 74.6410 - mse: 74.6410\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 81.1772 - mse: 81.1772\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 73.3854 - mse: 73.3854\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 74.4385 - mse: 74.4385\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 73.5168 - mse: 73.5168\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 87.0070 - mse: 87.0070\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 72.8440 - mse: 72.8440\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 77.4403 - mse: 77.4403\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 81.2123 - mse: 81.2123\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 86.8119 - mse: 86.8119\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 75.6218 - mse: 75.6218\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 77.1260 - mse: 77.1260\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 78.6900 - mse: 78.6900\n",
      "loss:  78.69002532958984\n",
      "mse:  78.69003295898438\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense\n",
    "from keras import optimizers\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Keras model with two hidden layer with 10 neurons each \n",
    "model.add(Dense(10, input_shape = (13,)))    # Input layer => input_shape should be explicitly designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))                          # Output layer => output dimension = 1 since it is regression problem\n",
    "\n",
    "'''\n",
    "This is equivalent to the above code block\n",
    ">> model.add(Dense(10, input_shape = (13,), activation = 'sigmoid'))\n",
    ">> model.add(Dense(10, activation = 'sigmoid'))\n",
    ">> model.add(Dense(10, activation = 'sigmoid'))\n",
    ">> model.add(Dense(1))\n",
    "'''\n",
    "\n",
    "sgd = optimizers.SGD(lr = 0.01)    # stochastic gradient descent optimizer\n",
    "\n",
    "model.compile(optimizer = sgd, loss = 'mean_squared_error', metrics = ['mse'])    # for regression problems, mean squared error (MSE) is often employed\n",
    "model.fit(X_train, y_train, batch_size = 50, epochs = 100, verbose = 1)\n",
    "\n",
    "results = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('loss: ', results[0])\n",
    "print('mse: ', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f255329c-d60c-48bf-bf47-0c7af0393c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "997a92cf-e2a7-4abb-a093-9579cc6f13ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13.836659 23.591133 23.591133 23.591133 23.591133 23.591133 23.591133\n",
      "  23.591133 23.591133 23.591133 13.836659 23.591133 23.591133 23.591133\n",
      "  23.591133 23.591133 23.591133 23.591133 23.591133 23.591133 23.591133\n",
      "  13.836659 23.591133 23.591133 23.591133 23.591133 23.591133 23.591133\n",
      "  13.836659 23.591133 23.591133 13.836659 23.591133 23.591133 23.591133\n",
      "  23.591133 23.591133 23.591133 23.591133 23.591133 23.591133 23.591133\n",
      "  23.591133 23.591133 23.591133 23.591133 23.591133 23.591133 23.591133\n",
      "  23.591133 23.591133 23.591133 23.591133 23.591133 23.591133 23.591133\n",
      "  23.591133 23.591133 23.591133 23.591133 23.591133 23.591133 13.836659\n",
      "  23.591133 23.591133 23.591133 23.591133 23.591133 23.591133 23.591133\n",
      "  23.591133 23.591133 23.591133 23.591133 23.591133 23.591133 23.591133\n",
      "  23.591133 23.591133 23.591133 23.591133 23.591133 23.591133 23.591133\n",
      "  23.591133 23.591133 23.591133 23.591133 23.591133 23.591133 23.591133\n",
      "  23.591133 23.591133 23.591133 23.591133 23.591133 23.591133 23.591133\n",
      "  23.591133 23.591133 23.591133 23.591133]]\n",
      "[ 7.2 18.8 19.  27.  22.2 24.5 31.2 22.9 20.5 23.2 18.6 14.5 17.8 50.\n",
      " 20.8 24.3 24.2 19.8 19.1 22.7 12.  10.2 20.  18.5 20.9 23.  27.5 30.1\n",
      "  9.5 22.  21.2 14.1 33.1 23.4 20.1  7.4 15.4 23.8 20.1 24.5 33.  28.4\n",
      " 14.1 46.7 32.5 29.6 28.4 19.8 20.2 25.  35.4 20.3  9.7 14.5 34.9 26.6\n",
      "  7.2 50.  32.4 21.6 29.8 13.1 27.5 21.2 23.1 21.9 13.  23.2  8.1  5.6\n",
      " 21.7 29.6 19.6  7.  26.4 18.9 20.9 28.1 35.4 10.2 24.3 43.1 17.6 15.4\n",
      " 16.2 27.1 21.4 21.5 22.4 25.  16.6 18.6 22.  42.8 35.1 21.5 36.  21.9\n",
      " 24.1 50.  26.7 25. ]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(y_pred.reshape(1,-1))\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e23d9b5-8fe3-4253-9788-7caeddfc5cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 502.6764 - mse: 502.6764\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 226.3476 - mse: 226.3476\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 127.0846 - mse: 127.0846\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 93.3073 - mse: 93.3073\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 93.9302 - mse: 93.9302\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 86.5100 - mse: 86.5100\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 77.0440 - mse: 77.0440\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 72.8144 - mse: 72.8144\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 87.8306 - mse: 87.8306\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 83.9073 - mse: 83.9073\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 83.9060 - mse: 83.9060\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 89.4727 - mse: 89.4727\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 83.0706 - mse: 83.0706\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 89.3372 - mse: 89.3372\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 87.4299 - mse: 87.4299\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 83.6093 - mse: 83.6093\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 81.5605 - mse: 81.5605\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 74.4919 - mse: 74.4919\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 84.4271 - mse: 84.4271\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 84.0851 - mse: 84.0851\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 80.8081 - mse: 80.8081\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 78.9273 - mse: 78.9273\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 86.4470 - mse: 86.4470\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.5513 - mse: 84.5513\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 69.4287 - mse: 69.4287\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 83.6044 - mse: 83.6044\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 80.1725 - mse: 80.1725\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 72.1413 - mse: 72.1413\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.0978 - mse: 84.0978\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 78.7527 - mse: 78.7527\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 76.3947 - mse: 76.3947\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 86.2099 - mse: 86.2099\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 79.6187 - mse: 79.6187\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 70.5574 - mse: 70.5574\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 67.3702 - mse: 67.3702\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 74.6513 - mse: 74.6513\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 67.0588 - mse: 67.0588\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 66.0903 - mse: 66.0903\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 77.8312 - mse: 77.8312\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 83.0276 - mse: 83.0276\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 65.4629 - mse: 65.4629\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 62.6968 - mse: 62.6968\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 70.7982 - mse: 70.7982\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 68.1399 - mse: 68.1399\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 73.5437 - mse: 73.5437\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 72.4938 - mse: 72.4938\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 68.5013 - mse: 68.5013\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 64.6810 - mse: 64.6810\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 65.7258 - mse: 65.7258\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 72.4544 - mse: 72.4544\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 68.5262 - mse: 68.5262\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 63.4276 - mse: 63.4277\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 63.6494 - mse: 63.6494\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 72.2961 - mse: 72.2961\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 74.4090 - mse: 74.4090\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 65.2070 - mse: 65.2070\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 77.3892 - mse: 77.3892\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 65.3289 - mse: 65.3289\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 63.0305 - mse: 63.0305\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 72.9912 - mse: 72.9912\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 70.3440 - mse: 70.3440\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 74.6448 - mse: 74.6448\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 72.9229 - mse: 72.9229\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 74.0136 - mse: 74.0136\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 58.2429 - mse: 58.2429\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 66.1547 - mse: 66.1547\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 70.1228 - mse: 70.1228\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 63.7241 - mse: 63.7241\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 76.8304 - mse: 76.8304\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 77.9919 - mse: 77.9919\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 75.1318 - mse: 75.1318\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 69.1694 - mse: 69.1694\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 72.5351 - mse: 72.5351\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 73.2797 - mse: 73.2797\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 69.2246 - mse: 69.2246\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 55.9026 - mse: 55.902 - 0s 9ms/step - loss: 60.0305 - mse: 60.0305\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 66.6157 - mse: 66.6157\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 65.6823 - mse: 65.6823\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 67.1557 - mse: 67.1557\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 64.6720 - mse: 64.6720\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 71.0794 - mse: 71.0794\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 81.2961 - mse: 81.2961\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 68.6604 - mse: 68.6604\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 72.1656 - mse: 72.1656\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 67.1629 - mse: 67.1629\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 73.2704 - mse: 73.2704\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 70.2795 - mse: 70.2795\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 75.2022 - mse: 75.2022\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 63.1850 - mse: 63.1850\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 62.3954 - mse: 62.3954\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 68.3000 - mse: 68.3000\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 68.4770 - mse: 68.4770\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 67.7565 - mse: 67.7565\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 73.3755 - mse: 73.3755\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 71.4630 - mse: 71.4630\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 65.9374 - mse: 65.9374\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 77.6041 - mse: 77.6041\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 76.2605 - mse: 76.2605\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 76.0577 - mse: 76.0577\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 73.5881 - mse: 73.5881\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 65.4491 - mse: 65.4491\n",
      "loss:  65.4491195678711\n",
      "mse:  65.4491195678711\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Keras model with two hidden layer with 10 neurons each \n",
    "model.add(Dense(16, input_shape = (13,)))    # Input layer => input_shape should be explicitly designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(8))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(4))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))                          # Output layer => output dimension = 1 since it is regression problem\n",
    "\n",
    "'''\n",
    "This is equivalent to the above code block\n",
    ">> model.add(Dense(10, input_shape = (13,), activation = 'sigmoid'))\n",
    ">> model.add(Dense(10, activation = 'sigmoid'))\n",
    ">> model.add(Dense(10, activation = 'sigmoid'))\n",
    ">> model.add(Dense(1))\n",
    "'''\n",
    "\n",
    "sgd = optimizers.SGD(lr = 0.01)    # stochastic gradient descent optimizer\n",
    "\n",
    "model.compile(optimizer = sgd, loss = 'mean_squared_error', metrics = ['mse'])    # for regression problems, mean squared error (MSE) is often employed\n",
    "model.fit(X_train, y_train, batch_size = 50, epochs = 100, verbose = 1)\n",
    "\n",
    "results = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('loss: ', results[0])\n",
    "print('mse: ', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "796628d3-442d-441d-a745-7ead98e08623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12.474673 23.79263  23.79263  23.79263  23.79263  23.79263  23.79263\n",
      "  23.79263  23.79263  16.063995 12.474673 23.79263  23.79263  23.792633\n",
      "  16.063995 23.79263  23.79263  23.79263  16.063995 16.063995 16.063995\n",
      "  12.474673 23.79263  23.79263  23.79263  16.063995 23.79263  24.67052\n",
      "  12.474673 23.79263  23.79263  12.474673 23.79263  23.79263  16.063995\n",
      "  16.063995 23.79263  16.071918 16.063995 23.79263  23.79263  23.79263\n",
      "  16.063995 23.79263  23.79263  23.79263  23.79263  23.79263  16.063995\n",
      "  23.79263  24.670536 23.79263  16.063995 23.79263  23.79263  23.79263\n",
      "  16.063995 23.79263  23.79263  23.79263  16.063995 16.063995 14.832083\n",
      "  23.79263  23.79263  23.79263  16.063995 23.79263  16.063995 16.063995\n",
      "  16.063995 23.79263  16.063995 16.063995 23.79263  23.79263  23.79263\n",
      "  23.79263  23.79263  16.063995 23.79263  23.79263  23.79263  16.063995\n",
      "  23.79263  23.79263  16.063995 23.79263  23.79263  16.063995 23.79263\n",
      "  23.79263  23.79263  23.79263  23.792633 23.79263  23.79263  16.063995\n",
      "  23.79263  23.79263  23.79263  23.662868]]\n",
      "[ 7.2 18.8 19.  27.  22.2 24.5 31.2 22.9 20.5 23.2 18.6 14.5 17.8 50.\n",
      " 20.8 24.3 24.2 19.8 19.1 22.7 12.  10.2 20.  18.5 20.9 23.  27.5 30.1\n",
      "  9.5 22.  21.2 14.1 33.1 23.4 20.1  7.4 15.4 23.8 20.1 24.5 33.  28.4\n",
      " 14.1 46.7 32.5 29.6 28.4 19.8 20.2 25.  35.4 20.3  9.7 14.5 34.9 26.6\n",
      "  7.2 50.  32.4 21.6 29.8 13.1 27.5 21.2 23.1 21.9 13.  23.2  8.1  5.6\n",
      " 21.7 29.6 19.6  7.  26.4 18.9 20.9 28.1 35.4 10.2 24.3 43.1 17.6 15.4\n",
      " 16.2 27.1 21.4 21.5 22.4 25.  16.6 18.6 22.  42.8 35.1 21.5 36.  21.9\n",
      " 24.1 50.  26.7 25. ]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(y_pred.reshape(1,-1))\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceaa901-4dc6-4179-a2b7-42d17f542c43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant-course",
   "language": "python",
   "name": "quant-course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
